#!/usr/bin/env python3
"""
–û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º YOLOv8 –∏ Roboflow
"""

import argparse
import os
import cv2
import numpy as np
from pathlib import Path
from ultralytics import YOLO
from utils import ImageProcessor, Visualizer, RoboflowManager
import time

def parse_arguments():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(description='–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ —Å YOLOv8 –∏ Roboflow')
    
    parser.add_argument('--source', type=str, default='0',
                       help='–ò—Å—Ç–æ—á–Ω–∏–∫: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, –≤–∏–¥–µ–æ –∏–ª–∏ 0 –¥–ª—è –≤–µ–±-–∫–∞–º–µ—Ä—ã')
    
    parser.add_argument('--model', type=str, default='yolov8n.pt',
                       help='–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏')
    
    parser.add_argument('--conf', type=float, default=0.5,
                       help='–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (0.0-1.0)')
    
    parser.add_argument('--save', action='store_true',
                       help='–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã')
    
    parser.add_argument('--output', type=str, default='runs/detect',
                       help='–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    
    parser.add_argument('--show', action='store_true',
                       help='–ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —ç–∫—Ä–∞–Ω–µ')
    
    parser.add_argument('--roboflow-workspace', type=str,
                       help='Workspace –≤ Roboflow –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞—Å—Ç–æ–º–Ω–æ–π –º–æ–¥–µ–ª–∏')
    
    parser.add_argument('--roboflow-project', type=str,
                       help='–ü—Ä–æ–µ–∫—Ç –≤ Roboflow')
    
    parser.add_argument('--roboflow-version', type=int, default=1,
                       help='–í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏ –≤ Roboflow')
    
    return parser.parse_args()

def load_model(args):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
    print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã Roboflow, –ø—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –æ—Ç—Ç—É–¥–∞
    if args.roboflow_workspace and args.roboflow_project:
        try:
            rf_manager = RoboflowManager()
            if rf_manager.api_key:
                model = rf_manager.get_model(
                    args.roboflow_workspace, 
                    args.roboflow_project, 
                    args.roboflow_version
                )
                if model:
                    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å Roboflow: {args.roboflow_project}")
                    return model
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å Roboflow: {e}")
            print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å YOLOv8...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å YOLOv8
    try:
        model = YOLO(args.model)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å: {args.model}")
        return model
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return None

def detect_image(model, image_path, args):
    """–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
    print(f"üñºÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_path}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    image = ImageProcessor.load_image(image_path)
    if image is None:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
        return None
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é
    results = model(image, conf=args.conf)
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    detections = []
    for r in results:
        if r.boxes is not None:
            boxes = r.boxes.xyxy.cpu().numpy()  # –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox
            confs = r.boxes.conf.cpu().numpy()  # —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            classes = r.boxes.cls.cpu().numpy().astype(int)  # –∫–ª–∞—Å—Å—ã
            
            for i, (box, conf, cls) in enumerate(zip(boxes, confs, classes)):
                detections.append({
                    'bbox': box.tolist(),
                    'confidence': float(conf),
                    'class': int(cls)
                })
    
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {len(detections)}")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    if detections:
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
        class_names = model.names if hasattr(model, 'names') else None
        
        # –†–∏—Å—É–µ–º —Ä–∞–º–∫–∏
        result_image = ImageProcessor.draw_bboxes(image, detections, class_names)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if args.show:
            cv2.imshow('–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤', result_image)
            cv2.waitKey(0)
            cv2.destroyAllWindows()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if args.save:
            output_dir = Path(args.output)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            output_path = output_dir / f"result_{Path(image_path).name}"
            ImageProcessor.save_image(result_image, str(output_path))
            print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
        
        return result_image, detections
    
    return image, []

def detect_video(model, video_path, args):
    """–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –≤–∏–¥–µ–æ –∏–ª–∏ —Å –≤–µ–±-–∫–∞–º–µ—Ä—ã"""
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –≤–∏–¥–µ–æ
    if video_path == '0':
        cap = cv2.VideoCapture(0)  # –í–µ–±-–∫–∞–º–µ—Ä–∞
        print("üìπ –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å –≤–µ–±-–∫–∞–º–µ—Ä—ã...")
    else:
        cap = cv2.VideoCapture(video_path)
        print(f"üé¨ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ: {video_path}")
    
    if not cap.isOpened():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –≤–∏–¥–µ–æ")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–¥–µ–æ
    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å)
    out = None
    if args.save:
        output_dir = Path(args.output)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        output_path = output_dir / f"result_video.mp4"
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
        print(f"üíæ –í–∏–¥–µ–æ –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
    
    frame_count = 0
    start_time = time.time()
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é
            results = model(frame, conf=args.conf, verbose=False)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            detections = []
            for r in results:
                if r.boxes is not None:
                    boxes = r.boxes.xyxy.cpu().numpy()
                    confs = r.boxes.conf.cpu().numpy()
                    classes = r.boxes.cls.cpu().numpy().astype(int)
                    
                    for box, conf, cls in zip(boxes, confs, classes):
                        detections.append({
                            'bbox': box.tolist(),
                            'confidence': float(conf),
                            'class': int(cls)
                        })
            
            # –†–∏—Å—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            class_names = model.names if hasattr(model, 'names') else None
            result_frame = ImageProcessor.draw_bboxes(frame, detections, class_names)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ –∫–∞–¥—Ä
            cv2.putText(result_frame, f"Objects: {len(detections)}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(result_frame, f"Frame: {frame_count}", 
                       (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–¥—Ä
            if args.show:
                cv2.imshow('–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ (–Ω–∞–∂–º–∏—Ç–µ Q –¥–ª—è –≤—ã—Ö–æ–¥–∞)', result_frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–¥—Ä –≤ –≤–∏–¥–µ–æ
            if out is not None:
                out.write(result_frame)
            
            # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 30 –∫–∞–¥—Ä–æ–≤
            if frame_count % 30 == 0:
                elapsed = time.time() - start_time
                fps_real = frame_count / elapsed
                print(f"üé¨ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {frame_count}, FPS: {fps_real:.1f}")
    
    except KeyboardInterrupt:
        print("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    
    finally:
        # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
        cap.release()
        if out is not None:
            out.release()
        cv2.destroyAllWindows()
        
        elapsed = time.time() - start_time
        if frame_count > 0:
            print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {frame_count} –∫–∞–¥—Ä–æ–≤ –∑–∞ {elapsed:.1f}—Å")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    args = parse_arguments()
    
    print("üöÄ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤")
    print(f"üìÇ –ò—Å—Ç–æ—á–Ω–∏–∫: {args.source}")
    print(f"üéØ –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {args.conf}")
    print("-" * 50)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = load_model(args)
    if model is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")
        return
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
    source = args.source
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
    if source.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')):
        detect_image(model, source, args)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    elif source.startswith(('http://', 'https://')) and any(source.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.bmp']):
        detect_image(model, source, args)
    
    # –ò–Ω–∞—á–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –≤–∏–¥–µ–æ –∏–ª–∏ –≤–µ–±-–∫–∞–º–µ—Ä—É
    else:
        detect_video(model, source, args)
    
    print("‚ú® –†–∞–±–æ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

if __name__ == "__main__":
    main()